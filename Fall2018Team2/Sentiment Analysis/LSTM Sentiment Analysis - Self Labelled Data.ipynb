{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an Sequential LSTM to create a supervised learning approach for predicting the sentiment of an article. This notebook was adapted from https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and Packages Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudarshan/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./Sentiment Training Data/Classified Articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>https://www.wykop.pl/link/4223359/blockchain-a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>http://www.computerweekly.com/news/252434855/C...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>http://www.mcclatchydc.com/news/politics-gover...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>https://slashdot.org/submission/7844329/coinch...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>https://cointelegraph.com/news/philippines-sen...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name                                                URL  Sentiment\n",
       "0  Sudarshan  https://www.wykop.pl/link/4223359/blockchain-a...        0.0\n",
       "1  Sudarshan  http://www.computerweekly.com/news/252434855/C...       -1.0\n",
       "2  Sudarshan  http://www.mcclatchydc.com/news/politics-gover...       -1.0\n",
       "3  Sudarshan  https://slashdot.org/submission/7844329/coinch...       -1.0\n",
       "4  Sudarshan  https://cointelegraph.com/news/philippines-sen...       -1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Sentiment Training Data/Articles Reading Assignment.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>https://www.wykop.pl/link/4223359/blockchain-a...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>ciastka strona korzysta z plik w cookies w cel...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>http://www.computerweekly.com/news/252434855/C...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>santiago silver fotolia criminals using crypto...</td>\n",
       "      <td>6472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>http://www.mcclatchydc.com/news/politics-gover...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>franco ordo ez anita kumar fordonez mcclatchyd...</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>https://slashdot.org/submission/7844329/coinch...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>catch stories past week beyond slashdot story ...</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sudarshan</td>\n",
       "      <td>https://cointelegraph.com/news/philippines-sen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cointelegraph philippine senator leila de lima...</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name                                                URL  Sentiment  \\\n",
       "0  Sudarshan  https://www.wykop.pl/link/4223359/blockchain-a...        0.5   \n",
       "1  Sudarshan  http://www.computerweekly.com/news/252434855/C...        0.0   \n",
       "2  Sudarshan  http://www.mcclatchydc.com/news/politics-gover...        0.0   \n",
       "3  Sudarshan  https://slashdot.org/submission/7844329/coinch...        0.0   \n",
       "4  Sudarshan  https://cointelegraph.com/news/philippines-sen...        0.0   \n",
       "\n",
       "                                             Content  Content Length  \n",
       "0  ciastka strona korzysta z plik w cookies w cel...             347  \n",
       "1  santiago silver fotolia criminals using crypto...            6472  \n",
       "2  franco ordo ez anita kumar fordonez mcclatchyd...            5233  \n",
       "3  catch stories past week beyond slashdot story ...             310  \n",
       "4  cointelegraph philippine senator leila de lima...            1750  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna()\n",
    "data[\"Sentiment\"] += 1\n",
    "data[\"Sentiment\"] /= 2\n",
    "\n",
    "data[\"Content\"] = [\"\" for i in range(len(data))]\n",
    "data[\"Content Length\"] = [0 for i in range(len(data))]\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    x = row[\"URL\"]\n",
    "    \n",
    "    key_words = df1[df1[\"source_url\"] == x][:1][\"contents\"].values[0]\n",
    "    data.at[i, \"Content\"] = str(key_words)\n",
    "    data.at[i, \"Content Length\"] = len(key_words)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Vector Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_features = 2000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['Content'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Content'].values)\n",
    "X = pad_sequences(X, maxlen = max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 128)         256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 2000) (125, 2)\n",
      "(125, 2000) (125, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_dummies = []\n",
    "\n",
    "\n",
    "for y in data[\"Sentiment\"]:\n",
    "    if y > 0.5:\n",
    "        Y_dummies.append([y, (1-y)])\n",
    "    else:\n",
    "        Y_dummies.append([(1-y), y])\n",
    "\n",
    "Y_dummies = np.matrix(Y_dummies)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_dummies, test_size = 0.5, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "125/125 [==============================] - 15s 117ms/step - loss: nan - acc: 0.8240\n",
      "Epoch 2/7\n",
      "125/125 [==============================] - 13s 103ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 3/7\n",
      "125/125 [==============================] - 14s 109ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 4/7\n",
      "125/125 [==============================] - 13s 106ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 5/7\n",
      "125/125 [==============================] - 13s 108ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 6/7\n",
      "125/125 [==============================] - 14s 115ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 7/7\n",
      "125/125 [==============================] - 15s 120ms/step - loss: nan - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d0ad978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 7\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 3s 23ms/step\n",
      "score: nan\n",
      "acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign Sentiments\n",
    "Given that the RNN produces a probability of the sentiment of an article, we attempt to normalize the value and create binary assignments before exporting it for the time-series analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40732/40732 [==============================] - 998s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "output_data = df1\n",
    "output_data = output_data.drop(\"marks\",axis=1)\n",
    "\n",
    "    \n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(output_data['c'].values)\n",
    "X = tokenizer.texts_to_sequences(output_data['c'].values)\n",
    "X = pad_sequences(X, maxlen = max_features)\n",
    "\n",
    "predictions = model.predict(X, batch_size=batch_size, verbose=1, steps=None)\n",
    "\n",
    "predictions_assigned = []\n",
    "\n",
    "for i in predictions:\n",
    "    if i[0] > i[1]:\n",
    "        predictions_assigned.append(0)\n",
    "    else:\n",
    "        predictions_assigned.append(1)\n",
    "\n",
    "output_data[\"marks\"] = predictions_assigned\n",
    "\n",
    "output_data.to_csv(\"Articles with Sentiment.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_count = 0\n",
    "total_count = 0\n",
    "for i, row in df1.iterrows():\n",
    "    elais_sentiment = row[\"marks\"]\n",
    "    predicted_sentiment = predictions_assigned[i]\n",
    "    \n",
    "    if elais_sentiment == predicted_sentiment:\n",
    "        success_count += 1\n",
    "    \n",
    "    total_count += 1\n",
    "    \n",
    "    \n",
    "print(\"The accuracy on the manually labelled data set is {}\".format(float(success_count/total_count)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
